{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siddharth5723/AI-Powered-Regulatory-Compliance-Checker-for-Contracts/blob/main/Model_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3bjmwmkDk3_"
      },
      "source": [
        "MODEL RESEARCH:\n",
        "\n",
        "MODULE-1:\n",
        "\n",
        "Clause identification and risk Analysis Engine.\n",
        "\n",
        "Tasks it needs to perform:\n",
        "1. Clause extraction(NER + segmentation)\n",
        "\n",
        "2. Clause classification\n",
        "\n",
        "3. Risk Scoring\n",
        "\n",
        "4. Missing clause detection\n",
        "\n",
        "Suitable models:\n",
        "\n",
        "1. Hugging Face Legal-BERT\n",
        "\n",
        "2. Google AI BERT / RoBERTa\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wprpfnJOIa4i"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch scikit-learn evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc6iQl73L_z5"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYpt6AxpCs-k"
      },
      "outputs": [],
      "source": [
        "#Hugging Face Legal-Bert\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score , f1_score , accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K74ezlRJDR-"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"lex_glue\" , \"ledgar\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keXFS1ObJPia"
      },
      "outputs": [],
      "source": [
        "model_name = \"nlpaueb/legal-bert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(dataset[\"train\"].features[\"label\"].names)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNE4FZ-cK2FL"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "encoded_dataset = dataset.map(tokenize_function, batched=True)\n",
        "encoded_dataset.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_nAdnauLE4T"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    precision = precision_score(labels, predictions, average=\"macro\")\n",
        "    recall = recall_score(labels, predictions, average=\"macro\")\n",
        "    f1 = f1_score(labels, predictions, average=\"macro\")\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "500f35cc"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.30.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "588de614"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvHCu3qPN5-D"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./legalbert_results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMnBMeqEOKqR"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "vT-sGfqmOLPP",
        "outputId": "a3ea989f-65a3-459c-990b-465b6d295d11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  super().__init__(loader)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='68' max='22500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   68/22500 57:38 < 326:29:50, 0.02 it/s, Epoch 0.01/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU0d2AIcOM9e"
      },
      "outputs": [],
      "source": [
        "results = trainer.evaluate(encoded_dataset[\"test\"])\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKr7Ij5K0obE0gGuWqvPVy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}