{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siddharth5723/AI-Powered-Regulatory-Compliance-Checker-for-Contracts/blob/main/Model_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3bjmwmkDk3_"
      },
      "source": [
        "MODEL RESEARCH:\n",
        "\n",
        "MODULE-1:\n",
        "\n",
        "Clause identification and risk Analysis Engine.\n",
        "\n",
        "Tasks it needs to perform:\n",
        "1. Clause extraction(NER + segmentation)\n",
        "\n",
        "2. Clause classification\n",
        "\n",
        "3. Risk Scoring\n",
        "\n",
        "4. Missing clause detection\n",
        "\n",
        "Suitable models:\n",
        "\n",
        "1. Hugging Face Legal-BERT\n",
        "\n",
        "2. Google AI BERT / RoBERTa\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wprpfnJOIa4i"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers datasets torch scikit-learn evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc6iQl73L_z5"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYpt6AxpCs-k"
      },
      "outputs": [],
      "source": [
        "# #Hugging Face Legal-Bert\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# from datasets import load_dataset\n",
        "# from transformers import (\n",
        "#     AutoTokenizer,\n",
        "#     AutoModelForSequenceClassification,\n",
        "#     TrainingArguments,\n",
        "#     Trainer\n",
        "# )\n",
        "\n",
        "# from sklearn.metrics import precision_score, recall_score , f1_score , accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K74ezlRJDR-"
      },
      "outputs": [],
      "source": [
        "# dataset = load_dataset(\"lex_glue\" , \"ledgar\")\n",
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keXFS1ObJPia"
      },
      "outputs": [],
      "source": [
        "# model_name = \"nlpaueb/legal-bert-base-uncased\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     model_name,\n",
        "#     num_labels=len(dataset[\"train\"].features[\"label\"].names)\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNE4FZ-cK2FL"
      },
      "outputs": [],
      "source": [
        "# def tokenize_function(example):\n",
        "#     return tokenizer(\n",
        "#         example[\"text\"],\n",
        "#         padding=\"max_length\",\n",
        "#         truncation=True,\n",
        "#         max_length=512\n",
        "#     )\n",
        "\n",
        "# encoded_dataset = dataset.map(tokenize_function, batched=True)\n",
        "# encoded_dataset.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_nAdnauLE4T"
      },
      "outputs": [],
      "source": [
        "# def compute_metrics(eval_pred):\n",
        "#     logits, labels = eval_pred\n",
        "#     predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "#     precision = precision_score(labels, predictions, average=\"macro\")\n",
        "#     recall = recall_score(labels, predictions, average=\"macro\")\n",
        "#     f1 = f1_score(labels, predictions, average=\"macro\")\n",
        "#     acc = accuracy_score(labels, predictions)\n",
        "\n",
        "#     return {\n",
        "#         \"accuracy\": acc,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall,\n",
        "#         \"f1\": f1\n",
        "#     }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "500f35cc"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers==4.30.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "588de614"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvHCu3qPN5-D"
      },
      "outputs": [],
      "source": [
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./legalbert_results\",\n",
        "#     learning_rate=2e-5,\n",
        "#     per_device_train_batch_size=8,\n",
        "#     per_device_eval_batch_size=8,\n",
        "#     num_train_epochs=3,\n",
        "#     weight_decay=0.01,\n",
        "#     logging_dir=\"./logs\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMnBMeqEOKqR"
      },
      "outputs": [],
      "source": [
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=encoded_dataset[\"train\"],\n",
        "#     eval_dataset=encoded_dataset[\"validation\"],\n",
        "#     compute_metrics=compute_metrics,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT-sGfqmOLPP"
      },
      "outputs": [],
      "source": [
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU0d2AIcOM9e"
      },
      "outputs": [],
      "source": [
        "# results = trainer.evaluate(encoded_dataset[\"test\"])\n",
        "# print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "MODULE-2:\n",
        "\n",
        "Regulatory Update Tracking & Integration System\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1. Scraping legal databases\n",
        "\n",
        "2. Detecting regulatory changes\n",
        "\n",
        "3. Semantic comparison with existing contracts\n",
        "\n",
        "Suitable Models:\n",
        "A. Retrieval + Embeddings\n",
        "\n",
        "1. OpenAI Embeddings\n",
        "\n",
        "2. ** Sentence-BERT (SBERT)**\n",
        "\n",
        "3. Instructor-XL embeddings"
      ],
      "metadata": {
        "id": "JRHdBxE2S5k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #Sentence-BERT (SBERT)\n",
        "# !pip install sentence-transformers torch scikit-learn"
      ],
      "metadata": {
        "id": "EjCNKqqUTtKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "# #sentences = [\n",
        "#  #   \"The processor shall delete personal data upon request.\",\n",
        "#   #  \"The company must erase user information when asked.\",\n",
        "#    # \"Payment must be made within 30 days of invoice receipt.\"\n",
        "# #]\n",
        "\n",
        "# sentences = [\n",
        "#     \"The indemnifying party shall hold harmless the other party.\",\n",
        "#     \"The party agrees to compensate and protect the other party from liability.\",\n",
        "#     \"This agreement shall terminate after five years.\"\n",
        "# ]\n",
        "\n",
        "# embeddings = model.encode(sentences)\n",
        "# similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "# print(\"Cosine Similarity Matrix:\\n\")\n",
        "# print(similarity_matrix)\n",
        "\n",
        "# print(\"\\nSimilarity between sentence 1 and 2:\",\n",
        "#       similarity_matrix[0][1])\n",
        "\n",
        "# print(\"Similarity between sentence 1 and 3:\",\n",
        "#       similarity_matrix[0][2])"
      ],
      "metadata": {
        "id": "851dRAmYUK2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module-3\n",
        "\n",
        "Contract Modification & Deployment\n",
        "\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1. Suggest clause edits\n",
        "\n",
        "2. Rewrite non-compliant text\n",
        "\n",
        "3. Version control\n",
        "\n",
        "Suitable Models:\n",
        "A. Instruction-tuned LLMs\n",
        "  1. GPT-4\n",
        "  2. **LLaMA 3 Instruct**"
      ],
      "metadata": {
        "id": "r5fAmWvtVysW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import ollama\n",
        "\n",
        "# response = ollama.chat(\n",
        "#     model=\"llama3:8b-instruct-q4\",\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"system\",\n",
        "#             \"content\": \"You are a legal compliance expert.\"\n",
        "#         },\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": \"Does this clause violate GDPR? The company may retain personal data indefinitely.\"\n",
        "#         }\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# print(\"\\nModel Response:\\n\")\n",
        "# print(response[\"message\"][\"content\"])"
      ],
      "metadata": {
        "id": "vBGoVD3SgjD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODULE-4\n",
        "\n",
        "Multi-Platform Integration & Notification System\n",
        "\n",
        "Tasks:\n",
        "1. Trigger alerts\n",
        "2. Summarize compliance reports\n",
        "3. Auto email drafting\n",
        "\n",
        "Suitable Models:\n",
        "1. Lightweight models (DistilBERT) for quick classification.\n",
        "2. **GPT-4 for summarization**"
      ],
      "metadata": {
        "id": "tshtRB5RI51o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade openai\n"
      ],
      "metadata": {
        "id": "ji-C4OYGKFJP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from getpass import getpass\n",
        "\n",
        "# # Secure way (recommended)\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "wqc8uskgKH-z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from openai import OpenAI\n",
        "\n",
        "# # Initialize client\n",
        "# client = OpenAI()\n",
        "\n",
        "# # Example long legal-style text\n",
        "# text_to_summarize = \"\"\"\n",
        "# This agreement outlines the obligations of the data processor regarding\n",
        "# the handling, storage, and deletion of personal data. The processor shall\n",
        "# ensure that personal data is retained only for as long as necessary to fulfill\n",
        "# the purposes for which it was collected. The processor must implement\n",
        "# appropriate technical and organizational measures to ensure data security.\n",
        "# \"\"\"\n",
        "\n",
        "# response = client.chat.completions.create(\n",
        "#     model=\"gpt-4o\",\n",
        "#     messages=[\n",
        "#         {\"role\": \"system\", \"content\": \"You are a professional legal summarization assistant.\"},\n",
        "#         {\"role\": \"user\", \"content\": f\"Summarize the following text clearly and concisely:\\n\\n{text_to_summarize}\"}\n",
        "#     ],\n",
        "#     temperature=0.2\n",
        "# )\n",
        "\n",
        "# print(\"Summary:\\n\")\n",
        "# print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "bId9LKkxLNEG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #testing destilBERT Instead\n",
        "# !pip install transformers torch"
      ],
      "metadata": {
        "id": "WWtEgggJLzVM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import pipeline\n",
        "\n",
        "# classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\")\n",
        "\n",
        "# result = classifier(\"The company may retain personal data indefinitely.\")\n",
        "\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "tPtVLx94N1XZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TfeayFmoN7S3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgo7g/dOvkjZdj9hfg4Uw9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}