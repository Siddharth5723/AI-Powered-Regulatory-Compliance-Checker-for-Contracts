{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siddharth5723/AI-Powered-Regulatory-Compliance-Checker-for-Contracts/blob/main/Model_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3bjmwmkDk3_"
      },
      "source": [
        "MODEL RESEARCH:\n",
        "\n",
        "MODULE-1:\n",
        "\n",
        "Clause identification and risk Analysis Engine.\n",
        "\n",
        "Tasks it needs to perform:\n",
        "1. Clause extraction(NER + segmentation)\n",
        "\n",
        "2. Clause classification\n",
        "\n",
        "3. Risk Scoring\n",
        "\n",
        "4. Missing clause detection\n",
        "\n",
        "Suitable models:\n",
        "\n",
        "1. Hugging Face Legal-BERT\n",
        "\n",
        "2. Google AI BERT / RoBERTa\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wprpfnJOIa4i"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers datasets torch scikit-learn evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc6iQl73L_z5"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYpt6AxpCs-k"
      },
      "outputs": [],
      "source": [
        "# #Hugging Face Legal-Bert\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# from datasets import load_dataset\n",
        "# from transformers import (\n",
        "#     AutoTokenizer,\n",
        "#     AutoModelForSequenceClassification,\n",
        "#     TrainingArguments,\n",
        "#     Trainer\n",
        "# )\n",
        "\n",
        "# from sklearn.metrics import precision_score, recall_score , f1_score , accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K74ezlRJDR-"
      },
      "outputs": [],
      "source": [
        "# dataset = load_dataset(\"lex_glue\" , \"ledgar\")\n",
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keXFS1ObJPia"
      },
      "outputs": [],
      "source": [
        "# model_name = \"nlpaueb/legal-bert-base-uncased\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     model_name,\n",
        "#     num_labels=len(dataset[\"train\"].features[\"label\"].names)\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNE4FZ-cK2FL"
      },
      "outputs": [],
      "source": [
        "# def tokenize_function(example):\n",
        "#     return tokenizer(\n",
        "#         example[\"text\"],\n",
        "#         padding=\"max_length\",\n",
        "#         truncation=True,\n",
        "#         max_length=512\n",
        "#     )\n",
        "\n",
        "# encoded_dataset = dataset.map(tokenize_function, batched=True)\n",
        "# encoded_dataset.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_nAdnauLE4T"
      },
      "outputs": [],
      "source": [
        "# def compute_metrics(eval_pred):\n",
        "#     logits, labels = eval_pred\n",
        "#     predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "#     precision = precision_score(labels, predictions, average=\"macro\")\n",
        "#     recall = recall_score(labels, predictions, average=\"macro\")\n",
        "#     f1 = f1_score(labels, predictions, average=\"macro\")\n",
        "#     acc = accuracy_score(labels, predictions)\n",
        "\n",
        "#     return {\n",
        "#         \"accuracy\": acc,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall,\n",
        "#         \"f1\": f1\n",
        "#     }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "500f35cc"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers==4.30.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "588de614"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvHCu3qPN5-D"
      },
      "outputs": [],
      "source": [
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./legalbert_results\",\n",
        "#     learning_rate=2e-5,\n",
        "#     per_device_train_batch_size=8,\n",
        "#     per_device_eval_batch_size=8,\n",
        "#     num_train_epochs=3,\n",
        "#     weight_decay=0.01,\n",
        "#     logging_dir=\"./logs\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMnBMeqEOKqR"
      },
      "outputs": [],
      "source": [
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=encoded_dataset[\"train\"],\n",
        "#     eval_dataset=encoded_dataset[\"validation\"],\n",
        "#     compute_metrics=compute_metrics,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vT-sGfqmOLPP"
      },
      "outputs": [],
      "source": [
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU0d2AIcOM9e"
      },
      "outputs": [],
      "source": [
        "# results = trainer.evaluate(encoded_dataset[\"test\"])\n",
        "# print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "MODULE-2:\n",
        "\n",
        "Regulatory Update Tracking & Integration System\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1. Scraping legal databases\n",
        "\n",
        "2. Detecting regulatory changes\n",
        "\n",
        "3. Semantic comparison with existing contracts\n",
        "\n",
        "Suitable Models:\n",
        "A. Retrieval + Embeddings\n",
        "\n",
        "1. OpenAI Embeddings\n",
        "\n",
        "2. ** Sentence-BERT (SBERT)**\n",
        "\n",
        "3. Instructor-XL embeddings"
      ],
      "metadata": {
        "id": "JRHdBxE2S5k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #Sentence-BERT (SBERT)\n",
        "# !pip install sentence-transformers torch scikit-learn"
      ],
      "metadata": {
        "id": "EjCNKqqUTtKs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "# #sentences = [\n",
        "#  #   \"The processor shall delete personal data upon request.\",\n",
        "#   #  \"The company must erase user information when asked.\",\n",
        "#    # \"Payment must be made within 30 days of invoice receipt.\"\n",
        "# #]\n",
        "\n",
        "# sentences = [\n",
        "#     \"The indemnifying party shall hold harmless the other party.\",\n",
        "#     \"The party agrees to compensate and protect the other party from liability.\",\n",
        "#     \"This agreement shall terminate after five years.\"\n",
        "# ]\n",
        "\n",
        "# embeddings = model.encode(sentences)\n",
        "# similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "# print(\"Cosine Similarity Matrix:\\n\")\n",
        "# print(similarity_matrix)\n",
        "\n",
        "# print(\"\\nSimilarity between sentence 1 and 2:\",\n",
        "#       similarity_matrix[0][1])\n",
        "\n",
        "# print(\"Similarity between sentence 1 and 3:\",\n",
        "#       similarity_matrix[0][2])"
      ],
      "metadata": {
        "id": "851dRAmYUK2S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module-3\n",
        "\n",
        "Contract Modification & Deployment\n",
        "\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1. Suggest clause edits\n",
        "\n",
        "2. Rewrite non-compliant text\n",
        "\n",
        "3. Version control\n",
        "\n",
        "Suitable Models:\n",
        "A. Instruction-tuned LLMs\n",
        "  1. GPT-4\n",
        "  2. **LLaMA 3 Instruct**"
      ],
      "metadata": {
        "id": "r5fAmWvtVysW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import ollama\n",
        "\n",
        "# response = ollama.chat(\n",
        "#     model=\"llama3:8b-instruct-q4\",\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"system\",\n",
        "#             \"content\": \"You are a legal compliance expert.\"\n",
        "#         },\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": \"Does this clause violate GDPR? The company may retain personal data indefinitely.\"\n",
        "#         }\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# print(\"\\nModel Response:\\n\")\n",
        "# print(response[\"message\"][\"content\"])"
      ],
      "metadata": {
        "id": "vBGoVD3SgjD8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0cIZ9QNgtdH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMf0FqHYkQbd3zaJm8emKfN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}